import os
import asyncio
import subprocess
import textwrap
import logging
import requests
import random
from io import BytesIO
from gtts import gTTS
from PIL import Image, ImageDraw, ImageFont, ImageFilter, ImageEnhance
from telegram import Update
from telegram.ext import (
    Application,
    MessageHandler,
    CommandHandler,
    filters,
    ContextTypes,
)

logging.basicConfig(
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    level=logging.INFO,
)
logger = logging.getLogger(__name__)

TOKEN = os.environ.get("BOT_TOKEN")
UNSPLASH_KEY = os.environ.get("UNSPLASH_KEY")

HINDI_FONT = "/usr/share/fonts/truetype/noto-hindi.ttf"
FALLBACK_FONT = "/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf"
OUTPUT_DIR = "/tmp/videobot"

# Free background music URLs (royalty free)
MUSIC_LIST = [
    "https://www.soundhelix.com/examples/mp3/SoundHelix-Song-1.mp3",
    "https://www.soundhelix.com/examples/mp3/SoundHelix-Song-2.mp3",
    "https://www.soundhelix.com/examples/mp3/SoundHelix-Song-3.mp3",
]


def get_font(size):
    for font_path in [HINDI_FONT, FALLBACK_FONT]:
        if os.path.exists(font_path):
            try:
                return ImageFont.truetype(font_path, size)
            except Exception:
                continue
    return ImageFont.load_default()


def get_keywords(script):
    """Script ‡§∏‡•á keywords ‡§®‡§ø‡§ï‡§æ‡§≤‡•á‡§Ç image search ‡§ï‡•á ‡§≤‡§ø‡§è"""
    # Common Hindi words ‡§ú‡•ã image search ‡§ï‡•á ‡§≤‡§ø‡§è useless ‡§π‡•à‡§Ç
    stop_words = {
        "‡§π‡•à", "‡§π‡•à‡§Ç", "‡§ï‡§æ", "‡§ï‡•Ä", "‡§ï‡•á", "‡§Æ‡•á‡§Ç", "‡§î‡§∞", "‡§ï‡•ã", "‡§∏‡•á", "‡§™‡§∞",
        "‡§Ø‡§π", "‡§µ‡§π", "‡§ú‡•ã", "‡§ï‡§ø", "‡§è‡§ï", "‡§π‡§Æ", "‡§Ü‡§™", "‡§µ‡•á", "‡§á‡§∏", "‡§â‡§∏",
        "‡§≠‡•Ä", "‡§§‡•ã", "‡§π‡•Ä", "‡§®‡§π‡•Ä‡§Ç", "‡§ú‡§¨", "‡§§‡§ï", "‡§Ö‡§¨", "‡§•‡§æ", "‡§•‡•Ä", "‡§•‡•á",
        "‡§π‡•ã‡§§‡§æ", "‡§π‡•ã‡§§‡•Ä", "‡§π‡•ã‡§§‡•á", "‡§ï‡§ø‡§Ø‡§æ", "‡§ï‡§∞‡§®‡§æ", "‡§ï‡§∞‡§§‡•á", "‡§≤‡§ø‡§è", "‡§¨‡§π‡•Å‡§§",
        "‡§Ö‡§™‡§®‡•á", "‡§Ö‡§™‡§®‡•Ä", "‡§π‡§Æ‡§æ‡§∞‡•á", "‡§Ü‡§ú", "‡§ï‡§≤", "‡§Ø‡§π‡§æ‡§Å", "‡§µ‡§π‡§æ‡§Å", "‡§ï‡•à‡§∏‡•á",
        "‡§ï‡•ç‡§Ø‡§æ", "‡§ï‡•ç‡§Ø‡•ã‡§Ç", "‡§ï‡•å‡§®", "‡§ï‡§π‡§æ‡§Å", "‡§ú‡•à‡§∏‡•á", "‡§ê‡§∏‡•á", "‡§¨‡§æ‡§∞‡•á", "‡§¨‡§æ‡§§"
    }
    
    words = script.replace('‡•§', ' ').replace(',', ' ').split()
    keywords = [w for w in words if len(w) > 3 and w not in stop_words]
    
    # English keywords map (Unsplash English ‡§Æ‡•á‡§Ç search ‡§ï‡§∞‡§§‡§æ ‡§π‡•à)
    hindi_to_english = {
        "‡§≠‡§æ‡§∞‡§§": "India", "‡§¶‡•á‡§∂": "country India", "‡§á‡§§‡§ø‡§π‡§æ‡§∏": "history ancient",
        "‡§™‡•ç‡§∞‡§ï‡•É‡§§‡§ø": "nature", "‡§™‡§æ‡§®‡•Ä": "water river", "‡§™‡§π‡§æ‡§°‡§º": "mountain",
        "‡§ú‡§Ç‡§ó‡§≤": "forest", "‡§Ü‡§ï‡§æ‡§∂": "sky clouds", "‡§∏‡•Ç‡§∞‡§ú": "sunrise sunset",
        "‡§∞‡§æ‡§§": "night stars", "‡§∂‡§π‡§∞": "city urban", "‡§ó‡§æ‡§Å‡§µ": "village rural",
        "‡§ñ‡•á‡§§": "farm field", "‡§´‡•Ç‡§≤": "flowers", "‡§™‡•á‡§°‡§º": "trees forest",
        "‡§∏‡§Æ‡•Å‡§¶‡•ç‡§∞": "ocean sea", "‡§®‡§¶‡•Ä": "river", "‡§µ‡§ø‡§ú‡•ç‡§û‡§æ‡§®": "science technology",
        "‡§∂‡§ø‡§ï‡•ç‡§∑‡§æ": "education school", "‡§∏‡•ç‡§µ‡§æ‡§∏‡•ç‡§•‡•ç‡§Ø": "health wellness",
        "‡§ñ‡•á‡§≤": "sports", "‡§∏‡§Ç‡§ó‡•Ä‡§§": "music", "‡§ï‡§≤‡§æ": "art",
        "‡§µ‡•ç‡§Ø‡§æ‡§™‡§æ‡§∞": "business", "‡§§‡§ï‡§®‡•Ä‡§ï": "technology", "‡§Ö‡§Ç‡§§‡§∞‡§ø‡§ï‡•ç‡§∑": "space universe",
        "‡§Ø‡•Å‡§¶‡•ç‡§ß": "war history", "‡§∂‡§æ‡§Ç‡§§‡§ø": "peace", "‡§ß‡§∞‡•ç‡§Æ": "religion temple",
        "‡§™‡§∞‡§ø‡§µ‡§æ‡§∞": "family", "‡§¨‡§ö‡•ç‡§ö‡•á": "children", "‡§Æ‡§π‡§ø‡§≤‡§æ": "woman",
        "‡§∏‡§´‡§≤‡§§‡§æ": "success motivation", "‡§ú‡•Ä‡§µ‡§®": "life journey",
    }
    
    # Hindi keywords ‡§ï‡•ã English ‡§Æ‡•á‡§Ç translate ‡§ï‡§∞‡•á‡§Ç
    english_keywords = []
    for word in keywords[:5]:
        if word in hindi_to_english:
            english_keywords.append(hindi_to_english[word])
    
    if not english_keywords:
        english_keywords = ["india nature beautiful", "landscape", "background"]
    
    return english_keywords[0] if english_keywords else "beautiful landscape"


def download_background(keyword, job_dir):
    """Unsplash ‡§∏‡•á image download ‡§ï‡§∞‡•á‡§Ç"""
    try:
        url = f"https://api.unsplash.com/photos/random"
        params = {
            "query": keyword,
            "orientation": "landscape",
            "client_id": UNSPLASH_KEY,
        }
        response = requests.get(url, params=params, timeout=10)
        
        if response.status_code == 200:
            data = response.json()
            img_url = data["urls"]["regular"]
            img_response = requests.get(img_url, timeout=15)
            
            if img_response.status_code == 200:
                img_path = os.path.join(job_dir, "background.jpg")
                with open(img_path, "wb") as f:
                    f.write(img_response.content)
                logger.info(f"Background image downloaded: {keyword}")
                return img_path
    except Exception as e:
        logger.error(f"Image download error: {e}")
    
    return None


def download_music(job_dir):
    """Background music download ‡§ï‡§∞‡•á‡§Ç"""
    try:
        music_url = random.choice(MUSIC_LIST)
        music_path = os.path.join(job_dir, "music.mp3")
        response = requests.get(music_url, timeout=20)
        if response.status_code == 200:
            with open(music_path, "wb") as f:
                f.write(response.content)
            return music_path
    except Exception as e:
        logger.error(f"Music download error: {e}")
    return None


def create_frame_with_text(bg_path, words_so_far, all_words, frame_num, job_dir):
    """‡§è‡§ï frame ‡§¨‡§®‡§æ‡§è‡§Ç typewriter effect ‡§ï‡•á ‡§∏‡§æ‡§•"""
    W, H = 1280, 720
    
    # Background load ‡§ï‡§∞‡•á‡§Ç
    if bg_path and os.path.exists(bg_path):
        img = Image.open(bg_path).convert("RGB")
        img = img.resize((W, H), Image.LANCZOS)
        # ‡§•‡•ã‡§°‡§º‡§æ dark ‡§ï‡§∞‡•á‡§Ç text readable ‡§¨‡§®‡§æ‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è
        enhancer = ImageEnhance.Brightness(img)
        img = enhancer.enhance(0.45)
        # Blur effect
        img = img.filter(ImageFilter.GaussianBlur(radius=1.5))
    else:
        img = Image.new("RGB", (W, H), color=(10, 10, 30))
    
    draw = ImageDraw.Draw(img)
    
    # Gradient overlay (bottom ‡§™‡§∞ dark)
    overlay = Image.new("RGBA", (W, H), (0, 0, 0, 0))
    overlay_draw = ImageDraw.Draw(overlay)
    for i in range(H // 2, H):
        alpha = int(180 * (i - H // 2) / (H // 2))
        overlay_draw.line([(0, i), (W, i)], fill=(0, 0, 0, alpha))
    img = img.convert("RGBA")
    img = Image.alpha_composite(img, overlay)
    img = img.convert("RGB")
    draw = ImageDraw.Draw(img)
    
    # Current text (‡§ú‡•ã words ‡§Ö‡§¨ ‡§§‡§ï ‡§Ü ‡§ö‡•Å‡§ï‡•á ‡§π‡•à‡§Ç)
    current_text = " ".join(words_so_far)
    
    # Text ‡§ï‡•ã lines ‡§Æ‡•á‡§Ç wrap ‡§ï‡§∞‡•á‡§Ç
    main_font = get_font(58)
    lines = textwrap.wrap(current_text, width=25)
    
    # ‡§∏‡§ø‡§∞‡•ç‡§´ ‡§Ü‡§ñ‡§ø‡§∞‡•Ä 3 lines ‡§¶‡§ø‡§ñ‡§æ‡§è‡§Ç
    if len(lines) > 3:
        lines = lines[-3:]
    
    # Text position (center-bottom area)
    total_h = len(lines) * 75
    y_start = H - total_h - 80
    
    for i, line in enumerate(lines):
        y = y_start + i * 75
        is_last_line = (i == len(lines) - 1)
        
        # Shadow
        draw.text((W // 2 + 2, y + 2), line, font=main_font,
                  fill=(0, 0, 0), anchor="mm")
        
        # Last line highlighted (‡§®‡§Ø‡§æ word)
        color = (255, 230, 0) if is_last_line else (255, 255, 255)
        draw.text((W // 2, y), line, font=main_font,
                  fill=color, anchor="mm")
    
    # Bottom progress bar
    progress = len(words_so_far) / max(len(all_words), 1)
    bar_w = int((W - 100) * progress)
    draw.rectangle([50, H - 25, W - 50, H - 15], fill=(80, 80, 80))
    draw.rectangle([50, H - 25, 50 + bar_w, H - 15], fill=(255, 200, 0))
    
    frame_path = os.path.join(job_dir, f"frame_{frame_num:06d}.png")
    img.save(frame_path, "PNG")
    return frame_path


def create_video(script_text, job_id):
    """‡§™‡•Ç‡§∞‡•Ä video ‡§¨‡§®‡§æ‡§è‡§Ç"""
    job_dir = os.path.join(OUTPUT_DIR, job_id)
    os.makedirs(job_dir, exist_ok=True)

    # 1. Hindi Audio ‡§¨‡§®‡§æ‡§è‡§Ç
    logger.info(f"[{job_id}] Audio ‡§¨‡§® ‡§∞‡§π‡•Ä ‡§π‡•à...")
    audio_path = os.path.join(job_dir, "voice.mp3")
    tts = gTTS(text=script_text, lang="hi", slow=False)
    tts.save(audio_path)

    # 2. Audio duration ‡§®‡§ø‡§ï‡§æ‡§≤‡•á‡§Ç
    result = subprocess.run(
        ["ffprobe", "-v", "error", "-show_entries", "format=duration",
         "-of", "default=noprint_wrappers=1:nokey=1", audio_path],
        capture_output=True, text=True
    )
    try:
        audio_duration = float(result.stdout.strip())
    except Exception:
        audio_duration = 30.0

    # 3. Keywords ‡§∏‡•á background image ‡§≤‡•á‡§Ç
    logger.info(f"[{job_id}] Background image download ‡§π‡•ã ‡§∞‡§π‡•Ä ‡§π‡•à...")
    keyword = get_keywords(script_text)
    bg_path = download_background(keyword, job_dir)

    # 4. Background music download ‡§ï‡§∞‡•á‡§Ç
    logger.info(f"[{job_id}] Background music download ‡§π‡•ã ‡§∞‡§π‡•Ä ‡§π‡•à...")
    music_path = download_music(job_dir)

    # 5. Typewriter frames ‡§¨‡§®‡§æ‡§è‡§Ç
    logger.info(f"[{job_id}] Typewriter frames ‡§¨‡§® ‡§∞‡§π‡•á ‡§π‡•à‡§Ç...")
    
    words = script_text.replace('‡•§', ' ‡•§ ').split()
    words = [w for w in words if w.strip()]
    
    fps = 24
    total_frames = int(audio_duration * fps)
    frames_per_word = max(1, total_frames // max(len(words), 1))
    
    frame_files = []
    frame_num = 0
    
    for word_idx in range(len(words)):
        words_so_far = words[:word_idx + 1]
        
        # ‡§π‡§∞ word ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ï‡•Å‡§õ frames ‡§¨‡§®‡§æ‡§è‡§Ç
        for f in range(frames_per_word):
            frame_path = create_frame_with_text(
                bg_path, words_so_far, words, frame_num, job_dir
            )
            frame_files.append(frame_path)
            frame_num += 1
    
    # ‡§¨‡§ö‡•á ‡§π‡•Å‡§è frames (‡§Ö‡§ó‡§∞ audio ‡§≤‡§Ç‡§¨‡•Ä ‡§π‡•ã)
    while frame_num < total_frames:
        frame_path = create_frame_with_text(
            bg_path, words, words, frame_num, job_dir
        )
        frame_files.append(frame_path)
        frame_num += 1

    # 6. Frames ‡§∏‡•á video ‡§¨‡§®‡§æ‡§è‡§Ç
    logger.info(f"[{job_id}] Video render ‡§π‡•ã ‡§∞‡§π‡•Ä ‡§π‡•à... ({len(frame_files)} frames)")
    
    # Frame list file
    frames_list = os.path.join(job_dir, "frames.txt")
    with open(frames_list, "w") as f:
        for fp in frame_files:
            f.write(f"file '{fp}'\n")
            f.write(f"duration {1/fps:.4f}\n")
        f.write(f"file '{frame_files[-1]}'\n")

    video_silent = os.path.join(job_dir, "video_silent.mp4")
    subprocess.run([
        "ffmpeg", "-y",
        "-f", "concat", "-safe", "0",
        "-i", frames_list,
        "-vf", f"fps={fps},scale=1280:720,format=yuv420p",
        "-c:v", "libx264",
        "-preset", "fast",
        "-crf", "23",
        video_silent,
    ], capture_output=True, check=True)

    # 7. Voice + Music mix ‡§ï‡§∞‡•á‡§Ç ‡§´‡§ø‡§∞ Video ‡§∏‡•á ‡§ú‡•ã‡§°‡§º‡•á‡§Ç
    logger.info(f"[{job_id}] Audio mix ‡§î‡§∞ final video ‡§¨‡§® ‡§∞‡§π‡•Ä ‡§π‡•à...")
    final_video = os.path.join(job_dir, "final_video.mp4")

    if music_path and os.path.exists(music_path):
        # Voice + Music mix (voice loud, music soft)
        mixed_audio = os.path.join(job_dir, "mixed_audio.aac")
        subprocess.run([
            "ffmpeg", "-y",
            "-i", audio_path,
            "-i", music_path,
            "-filter_complex",
            "[0:a]volume=1.8[voice];[1:a]volume=0.15,atrim=0:"+str(audio_duration)+"[music];[voice][music]amix=inputs=2:duration=first[aout]",
            "-map", "[aout]",
            "-c:a", "aac",
            "-b:a", "192k",
            mixed_audio,
        ], capture_output=True, check=True)

        subprocess.run([
            "ffmpeg", "-y",
            "-i", video_silent,
            "-i", mixed_audio,
            "-c:v", "copy",
            "-c:a", "copy",
            "-shortest",
            final_video,
        ], capture_output=True, check=True)
    else:
        # ‡§∏‡§ø‡§∞‡•ç‡§´ voice (music ‡§®‡§π‡•Ä‡§Ç ‡§Æ‡§ø‡§≤‡•Ä)
        subprocess.run([
            "ffmpeg", "-y",
            "-i", video_silent,
            "-i", audio_path,
            "-c:v", "copy",
            "-c:a", "aac",
            "-b:a", "192k",
            "-shortest",
            final_video,
        ], capture_output=True, check=True)

    logger.info(f"[{job_id}] ‚úÖ Video ‡§§‡•à‡§Ø‡§æ‡§∞!")
    return final_video


def cleanup(job_id):
    import shutil
    job_dir = os.path.join(OUTPUT_DIR, job_id)
    if os.path.exists(job_dir):
        shutil.rmtree(job_dir)


async def start_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text(
        "üé¨ ‡§®‡§Æ‡§∏‡•ç‡§§‡•á! ‡§Æ‡•à‡§Ç Script-to-Video Bot ‡§π‡•Ç‡§Å!\n\n"
        "‚ú® ‡§Æ‡•à‡§Ç ‡§Ü‡§™‡§ï‡•Ä script ‡§∏‡•á ‡§¨‡§®‡§æ‡§ä‡§Å‡§ó‡§æ:\n"
        "üñºÔ∏è Script ‡§∏‡•á matching background image\n"
        "‚å®Ô∏è Typewriter style animated text\n"
        "üéµ Background music\n"
        "üéôÔ∏è Hindi voice over\n\n"
        "üìù ‡§¨‡§∏ ‡§Ö‡§≠‡•Ä ‡§ï‡•ã‡§à Hindi script ‡§≠‡•á‡§ú‡•á‡§Ç! üëá"
    )


async def handle_script(update: Update, context: ContextTypes.DEFAULT_TYPE):
    script = update.message.text.strip()
    user_id = update.effective_user.id
    job_id = f"job_{user_id}_{update.message.message_id}"

    if len(script) < 15:
        await update.message.reply_text("‚ö†Ô∏è Script ‡§¨‡§π‡•Å‡§§ ‡§õ‡•ã‡§ü‡•Ä ‡§π‡•à! ‡§•‡•ã‡§°‡§º‡§æ ‡§î‡§∞ ‡§≤‡§ø‡§ñ‡•á‡§Ç‡•§")
        return

    if len(script) > 2000:
        await update.message.reply_text("‚ö†Ô∏è Script ‡§¨‡§π‡•Å‡§§ ‡§≤‡§Ç‡§¨‡•Ä ‡§π‡•à! 2000 characters ‡§∏‡•á ‡§ï‡§Æ ‡§∞‡§ñ‡•á‡§Ç‡•§")
        return

    msg = await update.message.reply_text(
        "üé¨ Video ‡§¨‡§® ‡§∞‡§π‡•Ä ‡§π‡•à...\n\n"
        "üîç Script analyze ‡§π‡•ã ‡§∞‡§π‡•Ä ‡§π‡•à\n"
        "üñºÔ∏è Background image download ‡§π‡•ã ‡§∞‡§π‡•Ä ‡§π‡•à\n"
        "üéµ Music load ‡§π‡•ã ‡§∞‡§π‡•Ä ‡§π‡•à\n"
        "üéôÔ∏è Hindi voice ‡§¨‡§® ‡§∞‡§π‡•Ä ‡§π‡•à\n"
        "‚å®Ô∏è Typewriter animation ‡§¨‡§® ‡§∞‡§π‡•Ä ‡§π‡•à\n\n"
        "‚è≥ 3-5 ‡§Æ‡§ø‡§®‡§ü ‡§≤‡§ó‡•á‡§Ç‡§ó‡•á..."
    )

    try:
        video_path = await asyncio.get_event_loop().run_in_executor(
            None, create_video, script, job_id
        )

        await msg.delete()
        with open(video_path, "rb") as v:
            await update.message.reply_video(
                video=v,
                caption=(
                    "‚úÖ ‡§Ü‡§™‡§ï‡•Ä Video ‡§§‡•à‡§Ø‡§æ‡§∞ ‡§π‡•à!\n\n"
                    "üñºÔ∏è Smart background image\n"
                    "‚å®Ô∏è Typewriter animation\n"
                    "üéµ Background music\n"
                    "üéôÔ∏è Hindi voice over\n\n"
                    "‡§®‡§à video ‡§ï‡•á ‡§≤‡§ø‡§è ‡§®‡§à script ‡§≠‡•á‡§ú‡•á‡§Ç! üé¨"
                ),
                supports_streaming=True,
            )

    except subprocess.CalledProcessError as e:
        logger.error(f"FFmpeg error: {e}")
        await msg.edit_text("‚ùå Video ‡§¨‡§®‡§æ‡§®‡•á ‡§Æ‡•á‡§Ç error! ‡§¶‡•ã‡§¨‡§æ‡§∞‡§æ try ‡§ï‡§∞‡•á‡§Ç‡•§")
    except Exception as e:
        logger.error(f"Error: {e}")
        await msg.edit_text("‚ùå ‡§ï‡•Å‡§õ ‡§ó‡§°‡§º‡§¨‡§°‡§º ‡§π‡•ã ‡§ó‡§à! ‡§¶‡•ã‡§¨‡§æ‡§∞‡§æ script ‡§≠‡•á‡§ú‡•á‡§Ç‡•§")
    finally:
        cleanup(job_id)


def main():
    if not TOKEN:
        raise ValueError("BOT_TOKEN ‡§®‡§π‡•Ä‡§Ç ‡§Æ‡§ø‡§≤‡§æ!")

    os.makedirs(OUTPUT_DIR, exist_ok=True)

    app = Application.builder().token(TOKEN).build()
    app.add_handler(CommandHandler("start", start_command))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_script))

    logger.info("‚úÖ Bot ‡§ö‡§æ‡§≤‡•Ç ‡§π‡•ã ‡§ó‡§Ø‡§æ!")
    app.run_polling(drop_pending_updates=True)


if __name__ == "__main__":
